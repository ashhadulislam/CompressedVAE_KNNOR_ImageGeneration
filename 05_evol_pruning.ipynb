{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from models import *\n",
    "from experiment import VAEXperiment\n",
    "import torch.backends.cudnn as cudnn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from dataset import VAEDataset\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# # Plot some training images\n",
    "# real_batch = next(iter(train_loader))\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "model_nm=\"VanillaVAE\"\n",
    "args_filename=\"configs/vae.yaml\"\n",
    "with open(args_filename, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "        \n",
    "        \n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "chk_path=\"logs/\"+model_nm+\"/version_2/checkpoints/last.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(chk_path,map_location=torch.device(device))\n",
    "        \n",
    "    \n",
    "data = VAEDataset(**config[\"data_params\"])\n",
    "data.setup()\n",
    "tloader=data.test_dataloader()\n",
    "train_loader=data.train_dataloader()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_mask_from_mean_wt(model,mean_weight_description,prune_rate):\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "#             print(nm)\n",
    "            mask_layer=torch.ones(params.shape)    \n",
    "            mean_wt_layer=mean_weight_description[nm]\n",
    "            wts_this_layer=[]\n",
    "            wts=mean_weight_description[nm]\n",
    "            abs_var=torch.std(wts.flatten())\n",
    "            threshold=abs_var*prune_rate\n",
    "            \n",
    "            these_wts=copy.deepcopy(params.data)\n",
    "            these_wts=these_wts.flatten()\n",
    "            mask_layer=mask_layer.flatten()\n",
    "            \n",
    "            for i in range(these_wts.shape[0]):\n",
    "                if torch.abs(these_wts[i])<threshold:\n",
    "                    mask_layer[i]=0\n",
    "            mask_layer=torch.reshape(mask_layer,params.data.shape)\n",
    "            print(nm,params.shape,mask_layer.shape,abs_var,threshold)\n",
    "            mask_whole_model.append(mask_layer)\n",
    "            \n",
    "    return mask_whole_model\n",
    "            \n",
    "    \n",
    "def get_weighted_mean(state_dicts,keyy,importance_vector):\n",
    "    sum_val=0\n",
    "    for i in range(len(importance_vector)):\n",
    "        importance=importance_vector[i]\n",
    "        wt_vals=state_dicts[i][keyy]\n",
    "        importance_wt_vals=importance*wt_vals\n",
    "        sum_val+=importance_wt_vals\n",
    "    return sum_val\n",
    "\n",
    "\n",
    "\n",
    "def apply_mask_model(model,list_mask_whole_model,layer_to_prune=None):\n",
    "    mask_layer_count=0\n",
    "    for nm, params in model.named_parameters():        \n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "#             print(mask_layer_count,layer_to_prune)\n",
    "            if layer_to_prune is not None:\n",
    "                if mask_layer_count>layer_to_prune:\n",
    "#                     print(mask_layer_count,layer_to_prune,\"returning model\")\n",
    "                    return model\n",
    "            \n",
    "            \n",
    "            mask_layer=list_mask_whole_model[mask_layer_count]\n",
    "            with torch.no_grad():\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#                 print(\"pruning layer\",mask_layer_count)\n",
    "                mask_layer=mask_layer.to(device)    \n",
    "                params.data=params.data*mask_layer            \n",
    "            mask_layer_count+=1\n",
    "    return model\n",
    "\n",
    "\n",
    "def nonzero(tensor):\n",
    "\n",
    "    return np.sum(tensor != 0.0)\n",
    "\n",
    "\n",
    "def model_size(model, as_bits=False):\n",
    "    \n",
    "    \n",
    "\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for tensor in model.parameters():\n",
    "        t = np.prod(tensor.shape)\n",
    "        nz = nonzero(tensor.detach().cpu().numpy())\n",
    "        if as_bits:\n",
    "            bits = dtype2bits[tensor.dtype]\n",
    "            t *= bits\n",
    "            nz *= bits\n",
    "        total_params += t\n",
    "        nonzero_params += nz\n",
    "    return int(total_params), int(nonzero_params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm=\"VanillaVAE\"\n",
    "args_filename=\"configs/vae.yaml\"\n",
    "with open(args_filename, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "        \n",
    "model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "chk_path=\"logs/\"+model_nm+\"/version_2/checkpoints/last.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(chk_path,map_location=torch.device(device))\n",
    "\n",
    "\n",
    "for nm,params in model.named_parameters():\n",
    "#     print(nm,params.shape)\n",
    "#     print(\"model.\"+nm in checkpoint[\"state_dict\"])\n",
    "    keyy=\"model.\"+nm \n",
    "    params.data=checkpoint[\"state_dict\"][keyy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.7147e-01, -5.4276e-02,  4.2360e-01],\n",
       "          [-5.5104e-01,  1.1627e-01,  4.9879e-01],\n",
       "          [-7.2046e-01,  1.8088e-01,  2.3496e-01]],\n",
       "\n",
       "         [[-4.8046e-01, -6.0694e-02,  4.9852e-01],\n",
       "          [-7.2104e-01,  2.4263e-01,  3.9929e-01],\n",
       "          [-2.5442e-01,  2.8318e-01,  7.1152e-01]],\n",
       "\n",
       "         [[-3.8183e-01, -1.0914e-01,  2.6411e-01],\n",
       "          [-4.9824e-01, -1.4876e-01,  5.2428e-01],\n",
       "          [-3.0802e-01, -1.7951e-01,  3.9325e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4050e-01,  7.1979e-02,  3.8273e-01],\n",
       "          [ 7.8096e-02, -1.8944e-01, -1.4746e-01],\n",
       "          [-1.1103e-01, -6.0413e-01, -3.3009e-01]],\n",
       "\n",
       "         [[ 4.6322e-01,  1.7154e-01,  4.7905e-01],\n",
       "          [ 3.0857e-01,  1.9879e-01,  1.2830e-01],\n",
       "          [ 1.3608e-01, -3.9847e-01, -2.5415e-01]],\n",
       "\n",
       "         [[ 3.0442e-01, -1.6816e-01,  1.8796e-02],\n",
       "          [-1.9579e-01, -6.0260e-01, -2.4356e-01],\n",
       "          [-6.1299e-02, -1.1389e+00, -6.5029e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.3294e-01,  8.4180e-01,  1.3514e+00],\n",
       "          [ 2.3889e-01,  1.2259e+00,  1.3332e+00],\n",
       "          [ 3.6586e-01,  9.1759e-01,  1.1061e+00]],\n",
       "\n",
       "         [[ 1.6440e-01,  3.1361e-01,  4.2321e-01],\n",
       "          [ 1.0501e-01,  1.4276e-01,  3.8415e-01],\n",
       "          [-1.1014e-01, -2.9910e-02,  2.8573e-01]],\n",
       "\n",
       "         [[-2.2740e-01, -8.1064e-02,  7.9885e-02],\n",
       "          [-1.1381e-01, -1.6345e-01,  1.2906e-01],\n",
       "          [-1.4697e-01, -2.8546e-01, -2.3240e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.2617e-01, -1.5469e+00, -6.5465e-01],\n",
       "          [-4.1564e-01, -2.4220e+00, -7.0418e-01],\n",
       "          [-3.7039e-01, -2.3000e+00, -1.0140e+00]],\n",
       "\n",
       "         [[ 2.5814e-01, -2.5091e-01,  1.8756e-01],\n",
       "          [ 2.9824e-02, -2.7028e-01, -2.0575e-01],\n",
       "          [-5.0862e-02, -1.9172e-01, -2.4161e-02]],\n",
       "\n",
       "         [[ 3.5860e-01,  1.9648e-01,  5.5505e-02],\n",
       "          [ 1.1665e-01,  6.8434e-02,  2.2241e-01],\n",
       "          [ 7.5830e-02, -1.5935e-01, -4.8761e-03]]],\n",
       "\n",
       "\n",
       "        [[[-6.6930e-02, -1.9736e-02, -6.5074e-02],\n",
       "          [-3.4364e-02,  3.9643e-01,  4.7596e-01],\n",
       "          [ 3.3575e-01,  4.2662e-01,  2.5564e-01]],\n",
       "\n",
       "         [[-1.6532e-01, -1.8005e-01,  1.1500e-01],\n",
       "          [ 2.9812e-01,  6.0029e-01,  6.6591e-01],\n",
       "          [ 5.9103e-01,  9.1377e-01,  6.6395e-01]],\n",
       "\n",
       "         [[-3.7862e-01, -2.8027e-01, -2.3173e-01],\n",
       "          [-1.1579e-02, -6.3454e-02, -1.5753e-01],\n",
       "          [ 1.0820e-01,  1.6703e-01,  9.2869e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.2009e-01,  4.5689e-01, -4.3598e-02],\n",
       "          [ 4.3138e-01, -1.8559e-01, -6.1634e-01],\n",
       "          [ 6.7847e-01,  1.2258e-01, -6.9213e-01]],\n",
       "\n",
       "         [[ 5.9472e-01,  2.0283e-01,  9.4125e-02],\n",
       "          [ 3.0923e-01, -4.4578e-03, -4.1168e-01],\n",
       "          [ 3.4622e-01, -1.3445e-01, -2.9526e-01]],\n",
       "\n",
       "         [[ 2.9541e-01,  8.0045e-02, -2.5146e-01],\n",
       "          [ 7.0534e-02,  7.6124e-02, -2.6915e-01],\n",
       "          [ 1.2371e-01,  1.0266e-01, -6.1662e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1215e+00, -5.9763e-01, -3.6729e-01],\n",
       "          [-1.0669e+00, -1.4589e-01,  1.3683e-02],\n",
       "          [-2.3788e-01,  2.7073e-01,  3.5488e-01]],\n",
       "\n",
       "         [[-4.9812e-01, -1.1179e-01, -5.4802e-02],\n",
       "          [-4.4336e-01,  5.9264e-02,  3.6481e-01],\n",
       "          [ 4.2862e-03,  2.7875e-01,  3.1798e-01]],\n",
       "\n",
       "         [[-4.8259e-02,  7.5384e-02,  4.0325e-02],\n",
       "          [-2.6462e-01,  4.0656e-02,  4.4681e-01],\n",
       "          [ 3.6547e-02,  9.2720e-02,  6.5542e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.3842e-01,  6.8791e-01,  5.1143e-01],\n",
       "          [-2.6799e-01,  3.5035e-01,  4.3660e-01],\n",
       "          [-1.4886e-01,  4.9427e-01,  4.3880e-01]],\n",
       "\n",
       "         [[-4.3781e-01,  7.2349e-01,  6.7562e-01],\n",
       "          [-4.2897e-01,  4.1889e-01,  4.1236e-01],\n",
       "          [-1.5584e-01,  6.6322e-01,  6.9502e-01]],\n",
       "\n",
       "         [[-1.4622e-01,  2.4086e-01,  2.6925e-01],\n",
       "          [-2.1038e-01, -6.6620e-02,  2.7596e-01],\n",
       "          [-2.3410e-01,  2.2803e-01,  3.7299e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.2595e-01,  1.3244e-01,  8.4052e-02],\n",
       "          [-1.9716e-01, -5.5762e-02, -1.5781e-01],\n",
       "          [-1.6884e-01, -9.8805e-02, -2.0173e-01]],\n",
       "\n",
       "         [[-5.4957e-02,  5.6501e-01,  4.0727e-01],\n",
       "          [-1.4280e-01,  6.1223e-01,  3.8671e-01],\n",
       "          [-9.3087e-02,  7.0882e-01,  3.0772e-01]],\n",
       "\n",
       "         [[-2.1695e-01,  4.1667e-01,  1.3961e-01],\n",
       "          [-2.5592e-01,  2.8958e-01,  4.9843e-01],\n",
       "          [-3.7055e-01,  6.3439e-01,  6.4304e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.1533e-01, -1.3724e+00, -5.5159e-01],\n",
       "          [-5.1237e-01, -1.1055e+00, -6.2328e-01],\n",
       "          [-4.0816e-01, -1.0317e+00, -8.0502e-01]],\n",
       "\n",
       "         [[-2.6780e-01, -3.1502e-01, -3.8788e-02],\n",
       "          [-5.6411e-02,  7.3947e-03, -1.0634e-01],\n",
       "          [ 2.8467e-02, -2.1309e-01, -1.2068e-01]],\n",
       "\n",
       "         [[ 1.0604e-01, -7.9289e-02, -9.0492e-02],\n",
       "          [ 2.3634e-01,  4.2440e-02,  7.2455e-02],\n",
       "          [ 2.7483e-01,  1.8718e-01, -6.5135e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.4520e-02,  1.1625e+00,  1.3095e+00],\n",
       "          [-3.3292e-01,  7.8138e-01,  6.5433e-01],\n",
       "          [-4.4897e-01,  3.6072e-01,  5.8527e-01]],\n",
       "\n",
       "         [[-1.5940e-01,  5.1231e-01,  4.8405e-01],\n",
       "          [-4.4350e-01,  2.8560e-01,  3.3550e-01],\n",
       "          [-3.7866e-01,  1.3725e-01, -8.6010e-02]],\n",
       "\n",
       "         [[-7.3608e-02,  2.0882e-01,  2.3659e-01],\n",
       "          [-2.9437e-01, -3.0859e-02, -1.3029e-01],\n",
       "          [-1.9989e-01, -2.0758e-01, -6.7126e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6836e-01, -6.7100e-01, -9.4863e-01],\n",
       "          [-1.3272e-01, -6.2611e-01, -1.1046e+00],\n",
       "          [-2.4253e-01, -8.1634e-01, -7.5165e-01]],\n",
       "\n",
       "         [[ 1.5596e-01, -1.5129e-01, -3.7870e-01],\n",
       "          [-1.8947e-01, -4.9216e-01, -4.5533e-01],\n",
       "          [-1.1383e-01, -5.0919e-01, -2.8319e-01]],\n",
       "\n",
       "         [[ 2.6527e-01,  2.1455e-01, -1.5551e-01],\n",
       "          [ 2.4711e-01, -2.7219e-02, -1.7913e-01],\n",
       "          [ 2.2892e-02,  7.1609e-02,  5.8904e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.3821e-01,  3.0469e-01,  3.2237e-02],\n",
       "          [ 6.2882e-02,  8.1513e-01,  4.9876e-01],\n",
       "          [-1.3085e-02,  8.4815e-01,  6.5174e-01]],\n",
       "\n",
       "         [[-3.4311e-01,  1.2810e-01, -2.2923e-02],\n",
       "          [-3.7592e-01,  3.4468e-01, -5.9701e-02],\n",
       "          [-2.0180e-01,  1.1027e-01,  7.3383e-02]],\n",
       "\n",
       "         [[-4.3241e-01,  1.7732e-01, -1.7686e-01],\n",
       "          [-1.6698e-01,  2.9585e-01, -2.5219e-02],\n",
       "          [ 5.3600e-02,  1.4416e-01,  2.0679e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.0380e-02,  4.5822e-02,  8.8573e-02],\n",
       "          [-1.6125e-01, -1.8139e-01,  1.0968e-01],\n",
       "          [-4.5106e-02,  2.7107e-02, -5.4207e-02]],\n",
       "\n",
       "         [[ 2.5433e-01, -6.1643e-02, -2.1771e-01],\n",
       "          [-3.6137e-01, -6.9155e-01, -5.0514e-01],\n",
       "          [-4.5606e-01, -7.5333e-01, -7.1204e-01]],\n",
       "\n",
       "         [[-1.9534e-02, -1.0554e+00, -1.6941e-01],\n",
       "          [-4.3510e-01, -1.2453e+00, -8.5510e-01],\n",
       "          [-6.3414e-01, -1.2256e+00, -9.9064e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.1573e-01, -8.3609e-02,  7.8308e-02],\n",
       "          [-9.2818e-02, -2.6887e-01, -3.1548e-01],\n",
       "          [-2.3970e-01, -9.5721e-02, -3.5005e-02]],\n",
       "\n",
       "         [[ 2.3485e-01, -5.3253e-01, -3.1384e-01],\n",
       "          [-1.7849e-01, -1.2165e+00, -5.8132e-01],\n",
       "          [-5.3101e-01, -1.0496e+00, -5.7053e-01]],\n",
       "\n",
       "         [[ 2.2004e-01, -3.5210e-01, -4.2875e-01],\n",
       "          [-2.6447e-02, -5.0853e-01, -2.4130e-01],\n",
       "          [-4.0785e-01, -6.5377e-01, -3.5563e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9039e-01,  4.7908e-02,  2.3023e-01],\n",
       "          [ 2.0074e-01, -7.9542e-02,  8.5983e-02],\n",
       "          [ 1.7937e-01, -7.7844e-02,  2.2712e-01]],\n",
       "\n",
       "         [[ 4.7557e-01, -4.9487e-02,  2.3082e-01],\n",
       "          [ 3.8428e-01,  1.3330e-01,  2.6079e-01],\n",
       "          [ 6.1863e-01,  3.1914e-01,  4.8662e-01]],\n",
       "\n",
       "         [[ 9.5985e-02,  1.2535e-01,  1.9314e-01],\n",
       "          [ 3.0992e-01,  2.9453e-01,  1.2534e-01],\n",
       "          [ 3.7961e-01,  1.6353e-01,  3.7258e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1816e-01,  5.0854e-02, -3.4119e-01],\n",
       "          [ 2.2088e-01, -3.0662e-01, -9.4912e-01],\n",
       "          [ 1.2682e-01, -4.3566e-01, -7.5463e-01]],\n",
       "\n",
       "         [[ 1.4782e-01, -2.9697e-01, -5.9754e-01],\n",
       "          [-1.9207e-01, -6.2020e-01, -1.0282e+00],\n",
       "          [-1.3180e-02, -3.7141e-01, -1.1129e+00]],\n",
       "\n",
       "         [[ 3.7162e-01, -8.1506e-02, -4.1157e-01],\n",
       "          [ 1.9752e-01, -3.6710e-01, -2.4927e-01],\n",
       "          [-1.0603e-01, -9.8083e-02, -3.1220e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.4579e-01, -4.9388e-03,  2.2056e-01],\n",
       "          [ 8.2361e-02,  5.1125e-01,  6.5253e-01],\n",
       "          [ 6.9020e-02, -7.4559e-02,  4.0851e-01]],\n",
       "\n",
       "         [[-8.4010e-01, -7.7417e-01, -4.3718e-01],\n",
       "          [ 8.1677e-02,  3.9292e-03,  3.2134e-01],\n",
       "          [-3.4648e-01, -2.0263e-01,  4.8051e-03]],\n",
       "\n",
       "         [[-4.4445e-01, -3.5407e-01,  2.0354e-02],\n",
       "          [ 2.5593e-01,  3.9916e-01,  3.9465e-01],\n",
       "          [-2.3870e-01,  5.7105e-02, -1.0855e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4827e-01,  3.3113e-01,  2.5417e-02],\n",
       "          [-1.9515e-01,  5.7559e-02,  1.1541e-01],\n",
       "          [-9.5726e-02,  1.4482e-01,  8.1786e-02]],\n",
       "\n",
       "         [[ 2.2021e-02,  1.1672e+00,  9.1249e-01],\n",
       "          [-3.3178e-01,  7.5276e-01,  2.5982e-01],\n",
       "          [-2.7571e-01,  9.5021e-01,  5.1100e-01]],\n",
       "\n",
       "         [[ 1.8865e-01,  3.7556e-01,  5.6878e-01],\n",
       "          [-1.4790e-02,  4.0102e-01,  1.1117e-01],\n",
       "          [-4.7931e-02,  4.0919e-01,  1.5678e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.1342e-02, -1.9965e-02,  2.2121e-01],\n",
       "          [ 2.3607e-01, -1.3793e-01, -5.8416e-02],\n",
       "          [ 4.6194e-01,  1.8048e-01,  2.8228e-01]],\n",
       "\n",
       "         [[-3.3850e-01, -5.0413e-01, -2.8387e-01],\n",
       "          [-4.5792e-01, -7.4376e-01, -4.6083e-01],\n",
       "          [-3.9864e-03, -4.2649e-01, -3.9100e-01]],\n",
       "\n",
       "         [[-6.3708e-01, -6.4223e-01, -5.7774e-01],\n",
       "          [-5.9340e-01, -9.8975e-01, -9.5578e-01],\n",
       "          [ 2.2782e-01, -1.0437e-01, -6.3658e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9473e-01,  2.2840e-01,  2.9783e-01],\n",
       "          [ 4.5302e-01,  8.0024e-01,  7.5341e-01],\n",
       "          [ 1.7835e-01,  3.3128e-01,  5.5036e-01]],\n",
       "\n",
       "         [[-3.3110e-01,  1.6557e-01,  1.7819e-01],\n",
       "          [ 2.0396e-01,  1.8945e-01,  3.0033e-01],\n",
       "          [-8.1492e-02,  3.0880e-01,  1.4668e-01]],\n",
       "\n",
       "         [[-2.1609e-01, -6.5422e-02, -1.7022e-02],\n",
       "          [-2.0034e-01,  3.4783e-01,  3.7282e-01],\n",
       "          [-8.3568e-02,  2.3214e-01,  2.3538e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2009e-01, -5.7659e-01, -5.7096e-01],\n",
       "          [-6.7326e-02, -3.2900e-01, -4.3394e-01],\n",
       "          [ 1.8048e-01,  3.3011e-02, -3.3755e-01]],\n",
       "\n",
       "         [[ 2.1029e-01, -5.8543e-01, -3.7913e-01],\n",
       "          [ 4.4063e-01, -2.3320e-01, -6.0437e-01],\n",
       "          [ 6.9566e-01, -8.9659e-02, -2.2484e-01]],\n",
       "\n",
       "         [[-1.1899e-01, -7.9675e-01, -9.6426e-01],\n",
       "          [-1.2414e-01, -6.1853e-01, -6.5644e-01],\n",
       "          [ 2.7582e-01, -1.6757e-01, -6.7949e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0795e+00,  1.0475e+00,  7.1453e-01],\n",
       "          [ 8.2237e-01,  7.2300e-01,  4.7940e-01],\n",
       "          [ 7.1524e-01,  5.7629e-01,  4.6782e-01]],\n",
       "\n",
       "         [[ 1.2745e-01,  2.7732e-01, -1.3917e-01],\n",
       "          [-1.7708e-02, -3.5772e-02, -9.3839e-02],\n",
       "          [ 2.5149e-01, -7.5465e-03, -2.0738e-01]],\n",
       "\n",
       "         [[ 2.3073e-01, -2.1739e-01, -2.9790e-01],\n",
       "          [-2.2926e-01,  2.0354e-02, -4.4193e-01],\n",
       "          [-1.5461e-01, -1.5714e-01, -3.3561e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.6499e-02, -1.4305e-01, -1.1990e-01],\n",
       "          [-1.2519e-01,  1.7144e-01,  8.9740e-02],\n",
       "          [-5.0919e-03,  2.3173e-01,  2.1189e-01]],\n",
       "\n",
       "         [[-8.8226e-02, -2.0584e-01,  2.0573e-01],\n",
       "          [ 6.0834e-02, -8.2576e-02,  2.9744e-01],\n",
       "          [-1.2034e-01, -2.2101e-02,  6.1072e-01]],\n",
       "\n",
       "         [[-3.2612e-02,  2.2536e-01,  5.5056e-01],\n",
       "          [-1.7452e-02,  1.9952e-01,  8.6309e-01],\n",
       "          [ 4.5443e-02,  6.4676e-01,  1.3581e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.4056e-01, -2.2096e-02,  1.0931e-01],\n",
       "          [ 2.1033e-01,  1.2791e-01,  6.4669e-02],\n",
       "          [ 1.0552e-01,  1.6197e-01,  1.7212e-01]],\n",
       "\n",
       "         [[-4.2959e-01, -3.1811e-01, -4.5351e-01],\n",
       "          [ 1.4517e-01,  3.2820e-01,  4.2369e-01],\n",
       "          [ 2.4995e-01,  3.2736e-01,  2.7902e-01]],\n",
       "\n",
       "         [[-2.8053e-01,  5.8427e-02, -3.5991e-01],\n",
       "          [ 3.3090e-01,  7.7866e-01,  6.7220e-01],\n",
       "          [ 3.7298e-01,  9.0975e-01,  2.7603e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6965e-01,  3.8461e-01,  3.7172e-01],\n",
       "          [-1.2768e-01,  2.3458e-02,  3.0946e-01],\n",
       "          [-2.9928e-01,  2.1423e-02,  1.6499e-01]],\n",
       "\n",
       "         [[ 2.4768e-01,  9.6044e-01,  8.1883e-01],\n",
       "          [ 1.1852e-02,  7.5551e-01,  7.1892e-01],\n",
       "          [-6.3243e-02,  5.7532e-01,  4.9990e-01]],\n",
       "\n",
       "         [[ 1.7188e-01,  6.2757e-01,  4.6983e-01],\n",
       "          [ 7.3299e-03,  2.9014e-01,  5.3298e-01],\n",
       "          [-2.7606e-01,  1.2998e-01,  4.2486e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0235e-01,  1.7825e-01,  2.5756e-01],\n",
       "          [ 3.5716e-02, -3.9096e-02, -3.4190e-02],\n",
       "          [-6.2608e-01, -4.9342e-01, -4.5596e-01]],\n",
       "\n",
       "         [[ 9.7708e-02,  3.5164e-01, -4.3620e-02],\n",
       "          [-1.1484e-02,  5.7291e-02,  1.0627e-01],\n",
       "          [-5.5831e-01, -3.7682e-01, -6.2300e-01]],\n",
       "\n",
       "         [[ 4.4077e-01,  5.6975e-01,  5.0187e-01],\n",
       "          [ 3.3021e-01,  2.2287e-01, -9.4925e-02],\n",
       "          [-3.4120e-01, -3.4304e-01, -5.5692e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.8639e-01, -1.7897e-02, -2.6804e-01],\n",
       "          [-3.3456e-01, -1.6000e-01, -2.4780e-01],\n",
       "          [-1.1194e-01, -5.3187e-02, -9.9795e-02]],\n",
       "\n",
       "         [[-9.0333e-01, -1.5343e-01, -4.8410e-02],\n",
       "          [-1.0977e+00, -4.7367e-01, -3.7041e-01],\n",
       "          [-4.6504e-01, -3.9688e-01, -3.1726e-01]],\n",
       "\n",
       "         [[-5.5899e-01, -1.5658e-02, -2.4291e-01],\n",
       "          [-4.4089e-01, -3.1998e-01, -6.2604e-02],\n",
       "          [-3.8065e-01, -1.5002e-01, -2.2871e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.4420e-02,  1.7422e-01,  2.1958e-01],\n",
       "          [ 1.6751e-01,  4.9077e-02, -7.8474e-02],\n",
       "          [ 4.4650e-02, -1.0821e-01,  2.8158e-02]],\n",
       "\n",
       "         [[ 3.9497e-01,  3.2522e-01,  1.8960e-01],\n",
       "          [ 3.9726e-01, -5.9600e-02, -2.9267e-02],\n",
       "          [ 2.3117e-01, -9.5207e-02,  1.5571e-01]],\n",
       "\n",
       "         [[ 3.7968e-01,  4.7185e-01,  6.8052e-01],\n",
       "          [ 5.0697e-01,  1.2212e-01,  4.5425e-03],\n",
       "          [ 7.2696e-01,  3.9204e-01,  4.0737e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.1652e-02, -1.4529e-01, -3.2764e-01],\n",
       "          [ 3.0950e-01, -2.0015e-02,  1.5591e-02],\n",
       "          [ 7.7193e-02, -7.5240e-02, -2.5593e-01]],\n",
       "\n",
       "         [[ 4.2035e-01, -1.5021e-01,  1.1185e-02],\n",
       "          [ 3.7965e-01,  4.9555e-01,  2.8217e-01],\n",
       "          [ 2.3647e-01,  9.0271e-02,  5.9665e-02]],\n",
       "\n",
       "         [[ 6.2711e-01,  6.8921e-02, -1.1188e-01],\n",
       "          [ 8.3189e-01,  6.7929e-01,  7.7251e-02],\n",
       "          [ 7.7250e-01,  5.2792e-01, -4.3356e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4372e-01, -2.2361e-01, -1.1327e-01],\n",
       "          [ 1.6659e-01, -3.6482e-02, -7.7851e-02],\n",
       "          [-5.7624e-02,  2.1047e-01,  7.1156e-02]],\n",
       "\n",
       "         [[-3.3847e-01, -3.9496e-03, -3.5172e-01],\n",
       "          [ 1.6872e-01,  1.8803e-01,  3.0378e-01],\n",
       "          [-4.6966e-02,  1.4194e-01,  2.7765e-01]],\n",
       "\n",
       "         [[-3.7393e-02,  3.7439e-01,  5.2194e-04],\n",
       "          [ 3.7443e-01,  1.3263e+00,  8.4473e-01],\n",
       "          [ 1.7374e-01,  1.1500e+00,  7.8819e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.0180e-01,  9.3519e-02,  2.0431e-01],\n",
       "          [-7.6074e-01,  1.6979e-01,  1.1490e-01],\n",
       "          [-1.2089e+00, -5.9447e-03, -2.9007e-01]],\n",
       "\n",
       "         [[-1.0738e+00,  4.3521e-01,  1.1764e-02],\n",
       "          [-6.7965e-01,  4.7359e-02, -3.2654e-01],\n",
       "          [-1.0421e+00, -1.5010e-01, -6.1548e-01]],\n",
       "\n",
       "         [[-6.7554e-02,  8.1528e-01,  2.1550e-01],\n",
       "          [-1.1904e-01,  5.0874e-01,  3.2917e-01],\n",
       "          [-1.5027e-01,  2.8070e-01, -1.4142e-02]]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint[\"state_dict\"]['model.encoder.0.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/VanillaVAE/version_2/checkpoints/last.ckpt\n",
      "logs/VanillaVAE/version_2/checkpoints/epoch=2-step=7631.ckpt\n"
     ]
    }
   ],
   "source": [
    "state_dicts=[]\n",
    "epoch_names=[\"last.ckpt\",\"epoch=2-step=7631.ckpt\"]\n",
    "\n",
    "for epoch_name in epoch_names:\n",
    "    chk_path=\"logs/\"+model_nm+\"/version_2/checkpoints/\"+epoch_name\n",
    "    print(chk_path)\n",
    "    checkpoint = torch.load(chk_path,map_location=torch.device(device))\n",
    "    state_dict=checkpoint[\"state_dict\"]\n",
    "    state_dicts.append(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.0.1.weight', 'model.encoder.0.1.bias', 'model.encoder.0.1.running_mean', 'model.encoder.0.1.running_var', 'model.encoder.0.1.num_batches_tracked', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.1.1.weight', 'model.encoder.1.1.bias', 'model.encoder.1.1.running_mean', 'model.encoder.1.1.running_var', 'model.encoder.1.1.num_batches_tracked', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.2.1.weight', 'model.encoder.2.1.bias', 'model.encoder.2.1.running_mean', 'model.encoder.2.1.running_var', 'model.encoder.2.1.num_batches_tracked', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.3.1.weight', 'model.encoder.3.1.bias', 'model.encoder.3.1.running_mean', 'model.encoder.3.1.running_var', 'model.encoder.3.1.num_batches_tracked', 'model.encoder.4.0.weight', 'model.encoder.4.0.bias', 'model.encoder.4.1.weight', 'model.encoder.4.1.bias', 'model.encoder.4.1.running_mean', 'model.encoder.4.1.running_var', 'model.encoder.4.1.num_batches_tracked', 'model.fc_mu.weight', 'model.fc_mu.bias', 'model.fc_var.weight', 'model.fc_var.bias', 'model.decoder_input.weight', 'model.decoder_input.bias', 'model.decoder.0.0.weight', 'model.decoder.0.0.bias', 'model.decoder.0.1.weight', 'model.decoder.0.1.bias', 'model.decoder.0.1.running_mean', 'model.decoder.0.1.running_var', 'model.decoder.0.1.num_batches_tracked', 'model.decoder.1.0.weight', 'model.decoder.1.0.bias', 'model.decoder.1.1.weight', 'model.decoder.1.1.bias', 'model.decoder.1.1.running_mean', 'model.decoder.1.1.running_var', 'model.decoder.1.1.num_batches_tracked', 'model.decoder.2.0.weight', 'model.decoder.2.0.bias', 'model.decoder.2.1.weight', 'model.decoder.2.1.bias', 'model.decoder.2.1.running_mean', 'model.decoder.2.1.running_var', 'model.decoder.2.1.num_batches_tracked', 'model.decoder.3.0.weight', 'model.decoder.3.0.bias', 'model.decoder.3.1.weight', 'model.decoder.3.1.bias', 'model.decoder.3.1.running_mean', 'model.decoder.3.1.running_var', 'model.decoder.3.1.num_batches_tracked', 'model.final_layer.0.weight', 'model.final_layer.0.bias', 'model.final_layer.1.weight', 'model.final_layer.1.bias', 'model.final_layer.1.running_mean', 'model.final_layer.1.running_var', 'model.final_layer.1.num_batches_tracked', 'model.final_layer.3.weight', 'model.final_layer.3.bias'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.0.weight torch.Size([32, 3, 3, 3])\n",
      "encoder.0.1.weight torch.Size([32])\n",
      "encoder.1.0.weight torch.Size([64, 32, 3, 3])\n",
      "encoder.1.1.weight torch.Size([64])\n",
      "encoder.2.0.weight torch.Size([128, 64, 3, 3])\n",
      "encoder.2.1.weight torch.Size([128])\n",
      "encoder.3.0.weight torch.Size([256, 128, 3, 3])\n",
      "encoder.3.1.weight torch.Size([256])\n",
      "encoder.4.0.weight torch.Size([512, 256, 3, 3])\n",
      "encoder.4.1.weight torch.Size([512])\n",
      "fc_mu.weight torch.Size([128, 2048])\n",
      "fc_var.weight torch.Size([128, 2048])\n",
      "decoder_input.weight torch.Size([2048, 128])\n",
      "decoder.0.0.weight torch.Size([512, 256, 3, 3])\n",
      "decoder.0.1.weight torch.Size([256])\n",
      "decoder.1.0.weight torch.Size([256, 128, 3, 3])\n",
      "decoder.1.1.weight torch.Size([128])\n",
      "decoder.2.0.weight torch.Size([128, 64, 3, 3])\n",
      "decoder.2.1.weight torch.Size([64])\n",
      "decoder.3.0.weight torch.Size([64, 32, 3, 3])\n",
      "decoder.3.1.weight torch.Size([32])\n",
      "final_layer.0.weight torch.Size([32, 32, 3, 3])\n",
      "final_layer.1.weight torch.Size([32])\n",
      "final_layer.3.weight torch.Size([3, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "importance_vector=[0.8,0.2]\n",
    "evol_wts={}\n",
    "for nm,params in model.named_parameters():\n",
    "    if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "        print(nm,params.shape)\n",
    "        keyy=\"model.\"+nm         \n",
    "#         print(state_dicts[0][keyy].shape,state_dicts[1][keyy].shape)\n",
    "#         print(state_dicts[0][keyy][0],state_dicts[1][keyy][0])        \n",
    "        new_param_values=get_weighted_mean(state_dicts,keyy,importance_vector)\n",
    "#         print(new_param_values[0])\n",
    "        evol_wts[nm]=new_param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder.0.0.weight', 'encoder.0.1.weight', 'encoder.1.0.weight', 'encoder.1.1.weight', 'encoder.2.0.weight', 'encoder.2.1.weight', 'encoder.3.0.weight', 'encoder.3.1.weight', 'encoder.4.0.weight', 'encoder.4.1.weight', 'fc_mu.weight', 'fc_var.weight', 'decoder_input.weight', 'decoder.0.0.weight', 'decoder.0.1.weight', 'decoder.1.0.weight', 'decoder.1.1.weight', 'decoder.2.0.weight', 'decoder.2.1.weight', 'decoder.3.0.weight', 'decoder.3.1.weight', 'final_layer.0.weight', 'final_layer.1.weight', 'final_layer.3.weight'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evol_wts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.0.weight torch.Size([32, 3, 3, 3]) torch.Size([32, 3, 3, 3]) tensor(0.3757) tensor(0.0188)\n",
      "encoder.0.1.weight torch.Size([32]) torch.Size([32]) tensor(0.2073) tensor(0.0104)\n",
      "encoder.1.0.weight torch.Size([64, 32, 3, 3]) torch.Size([64, 32, 3, 3]) tensor(0.2704) tensor(0.0135)\n",
      "encoder.1.1.weight torch.Size([64]) torch.Size([64]) tensor(0.2865) tensor(0.0143)\n",
      "encoder.2.0.weight torch.Size([128, 64, 3, 3]) torch.Size([128, 64, 3, 3]) tensor(0.2718) tensor(0.0136)\n",
      "encoder.2.1.weight torch.Size([128]) torch.Size([128]) tensor(0.3943) tensor(0.0197)\n",
      "encoder.3.0.weight torch.Size([256, 128, 3, 3]) torch.Size([256, 128, 3, 3]) tensor(0.2684) tensor(0.0134)\n",
      "encoder.3.1.weight torch.Size([256]) torch.Size([256]) tensor(0.3330) tensor(0.0166)\n",
      "encoder.4.0.weight torch.Size([512, 256, 3, 3]) torch.Size([512, 256, 3, 3]) tensor(0.2204) tensor(0.0110)\n",
      "encoder.4.1.weight torch.Size([512]) torch.Size([512]) tensor(0.0931) tensor(0.0047)\n",
      "fc_mu.weight torch.Size([128, 2048]) torch.Size([128, 2048]) tensor(0.1266) tensor(0.0063)\n",
      "fc_var.weight torch.Size([128, 2048]) torch.Size([128, 2048]) tensor(0.0950) tensor(0.0048)\n",
      "decoder_input.weight torch.Size([2048, 128]) torch.Size([2048, 128]) tensor(0.4166) tensor(0.0208)\n",
      "decoder.0.0.weight torch.Size([512, 256, 3, 3]) torch.Size([512, 256, 3, 3]) tensor(0.3843) tensor(0.0192)\n",
      "decoder.0.1.weight torch.Size([256]) torch.Size([256]) tensor(0.2511) tensor(0.0126)\n",
      "decoder.1.0.weight torch.Size([256, 128, 3, 3]) torch.Size([256, 128, 3, 3]) tensor(0.4345) tensor(0.0217)\n",
      "decoder.1.1.weight torch.Size([128]) torch.Size([128]) tensor(0.2256) tensor(0.0113)\n",
      "decoder.2.0.weight torch.Size([128, 64, 3, 3]) torch.Size([128, 64, 3, 3]) tensor(0.4008) tensor(0.0200)\n",
      "decoder.2.1.weight torch.Size([64]) torch.Size([64]) tensor(0.1936) tensor(0.0097)\n",
      "decoder.3.0.weight torch.Size([64, 32, 3, 3]) torch.Size([64, 32, 3, 3]) tensor(0.3448) tensor(0.0172)\n",
      "decoder.3.1.weight torch.Size([32]) torch.Size([32]) tensor(0.1893) tensor(0.0095)\n",
      "final_layer.0.weight torch.Size([32, 32, 3, 3]) torch.Size([32, 32, 3, 3]) tensor(0.3308) tensor(0.0165)\n",
      "final_layer.1.weight torch.Size([32]) torch.Size([32]) tensor(0.1177) tensor(0.0059)\n",
      "final_layer.3.weight torch.Size([3, 32, 3, 3]) torch.Size([3, 32, 3, 3]) tensor(0.1131) tensor(0.0057)\n"
     ]
    }
   ],
   "source": [
    "# evol_wts\n",
    "prune_rate=0.05\n",
    "list_mask_val=create_mask_from_mean_wt(model,evol_wts,prune_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression is  0.05535987972475864\n"
     ]
    }
   ],
   "source": [
    "pruned_model=apply_mask_model(model,list_mask_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_size,nz_size=model_size(model)\n",
    "compression=(total_size-nz_size)/total_size\n",
    "print(\"compression is \",compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression is  0.4593346005914718\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_kernel",
   "language": "python",
   "name": "prune_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
